{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각종 라이브러리를 임포트 해줍시다. \n",
    "\n",
    "%matplotlib inline\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch, gc\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import glob\n",
    "from PIL import ExifTags\n",
    "import shutil\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각종 사용할 함수를 세팅합니다.\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    training_dir = \"D:/training/\"\n",
    "    testing_dir = \"D:/testing/\"\n",
    "    validation_dir = \"D:/validation/\"\n",
    "    train_batch_size = 64\n",
    "    train_number_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 지정\n",
    "folder_path = 'D:\\\\Face_data2'\n",
    "testing_folder = 'D:\\\\testing'\n",
    "training_folder = 'D:\\\\training'\n",
    "validation_folder = \"D:\\\\validation\"\n",
    "val_lis = []\n",
    "\n",
    "test_samples = 720 # testing 폴더 갯수\n",
    "val_sampes = 360 # validation 폴더 갯수\n",
    "random.seed(2023) # 랜덤시드 고정\n",
    "\n",
    "folders = next(os.walk(folder_path))[1] # D 드라이브에 있는 폴더를 가져오기\n",
    "test_folders = random.sample(folders, test_samples) # testing 폴더를 랜덤으로 뽑기\n",
    "for folder in folders:\n",
    "    if folder not in test_folders:\n",
    "        val_lis.append(folder)\n",
    "\n",
    "val_folders = random.sample(val_lis, val_sampes) # validation 폴더를 랜덤으로 뽑기\n",
    "\n",
    "# 폴더 생성\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "os.makedirs(testing_folder, exist_ok=True)\n",
    "os.makedirs(validation_folder, exist_ok=True)\n",
    "\n",
    "# testing 폴더에 복사\n",
    "for folder in test_folders:\n",
    "    source_path = os.path.join(folder_path, folder)\n",
    "    destination_path = os.path.join(testing_folder, folder)\n",
    "    shutil.copytree(source_path, destination_path)\n",
    "\n",
    "# validation 폴더에 복사\n",
    "for folder in val_folders:\n",
    "    source_path = os.path.join(folder_path, folder)\n",
    "    destination_path = os.path.join(validation_folder, folder)\n",
    "    shutil.copytree(source_path, destination_path)\n",
    "\n",
    "# 나머지는 training 폴더에 복사\n",
    "for folder in folders:\n",
    "    if folder not in test_folders and folder not in val_folders:\n",
    "        source_path = os.path.join(folder_path, folder)\n",
    "        destination_path = os.path.join(training_folder, folder)\n",
    "        shutil.copytree(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"D:\\\\testing\\\\**\"\n",
    "# rot_img = []\n",
    "# for f in glob.glob(path, recursive=True):\n",
    "#     try:\n",
    "#         img = Image.open(f)\n",
    "#         exif_data = img._getexif()\n",
    "#         if exif_data[274] != 1:\n",
    "#             print(f, exif_data[274])\n",
    "#             rot_img.append(img)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imageFolderDataset, transform=None, should_invert=True):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "\n",
    "    def rotate(self, img):\n",
    "        try:\n",
    "            if img._getexif()[274] not in [1, 2]:\n",
    "                orientation = img._getexif()[274]\n",
    "                 \n",
    "                if orientation == 2:\n",
    "                    img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "                elif orientation == 3:\n",
    "                    img = img.rotate(180)\n",
    "\n",
    "                elif orientation == 4:\n",
    "                    img = img.rotate(180).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "                elif orientation == 5:\n",
    "                    img = img.rotate(-90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "                elif orientation == 6:\n",
    "                    img = img.rotate(-90, expand=True)\n",
    "\n",
    "                elif orientation == 7:\n",
    "                    img = img.rotate(90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "            return img\n",
    "        except:\n",
    "            return img\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "        #we need to make sure approx 50% of images are in the same class\n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                #keep looping till the same class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1]==img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                #keep looping till a different class image is found\n",
    "                \n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] !=img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "\n",
    "        if img0._getexif() not in [1, 2]:\n",
    "            img0 = self.rotate(img0)\n",
    "        \n",
    "        if img1._getexif() not in [1, 2]:\n",
    "            img1 = self.rotate(img1)\n",
    "\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "        \n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)\n",
    "            img1 = PIL.ImageOps.invert(img1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "\n",
    "        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dir 경로 안의 모든 파일을 폴더명과 함께 튜플로 저장\n",
    "folder_dataset = dset.ImageFolder(root=Config.training_dir)\n",
    "folder_dataset[4]\n",
    "\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.CenterCrop((100,100)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ]),\n",
    "                                       should_invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 미니배치 생성기\n",
    "# vis_dataloader = DataLoader(siamese_dataset,\n",
    "#                         shuffle=True,\n",
    "#                         num_workers=0,\n",
    "#                         batch_size=8)\n",
    "# # 미니배치 세트 생성\n",
    "# dataiter = iter(vis_dataloader)\n",
    "\n",
    "# example_batch = next(dataiter)\n",
    "\n",
    "# concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
    "# imshow(torchvision.utils.make_grid(concatenated))\n",
    "# print(example_batch[2].numpy())\n",
    "# print(torchvision.utils.make_grid(concatenated).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SiameseNetwork1\n",
    "# class SiameseNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "#         self.cnn1 = nn.Sequential(\n",
    "#             nn.ReflectionPad2d(1),\n",
    "#             nn.Conv2d(1, 8, kernel_size=3),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.BatchNorm2d(8),\n",
    "            \n",
    "#             nn.ReflectionPad2d(1),\n",
    "#             nn.Conv2d(8, 16, kernel_size=3),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.BatchNorm2d(16),\n",
    "\n",
    "#             nn.ReflectionPad2d(1),\n",
    "#             nn.Conv2d(16, 16, kernel_size=3),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.BatchNorm2d(16),\n",
    "\n",
    "#         )\n",
    "\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(16*100*100, 500),\n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "#             nn.Linear(500, 500),\n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "#             nn.Linear(500, 2))\n",
    "\n",
    "#     def forward_once(self, x):\n",
    "#         output = self.cnn1(x)\n",
    "#         output = output.view(output.size()[0], -1)\n",
    "#         output = self.fc1(output)\n",
    "#         return output\n",
    "\n",
    "#     def forward(self, input1, input2):\n",
    "#         output1 = self.forward_once(input1)\n",
    "#         output2 = self.forward_once(input2)\n",
    "#         return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SiameseNetwork2\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(18432, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n"
     ]
    }
   ],
   "source": [
    "# train 데이터셋\n",
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        batch_size=Config.train_batch_size)\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation 데이터셋\n",
    "folder_dataset_val = dset.ImageFolder(root=Config.validation_dir)\n",
    "siamese_dataset_val = SiameseNetworkDataset(imageFolderDataset=folder_dataset_val,\n",
    "                                           transform=transforms.Compose([transforms.Resize((100, 100)),\n",
    "                                                                         transforms.ToTensor()]),\n",
    "                                           should_invert=False)\n",
    "validation_dataloader = DataLoader(siamese_dataset_val, num_workers=0, batch_size=8) \n",
    "print(len(validation_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping을 위해 validation loss를 계산하는 함수\n",
    "def calculate_validation_loss(model, criterion, dataloader):\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs1, inputs2, labels = data\n",
    "            inputs1 = inputs1.cuda()\n",
    "            inputs2 = inputs2.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            outputs1, outputs2 = model(inputs1, inputs2)\n",
    "            loss = criterion(outputs1, outputs2, labels)\n",
    "            \n",
    "            total_loss += loss.item() * len(inputs1)\n",
    "            total_samples += len(inputs1)\n",
    "    \n",
    "    average_loss = total_loss / total_samples\n",
    "\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 0\n",
      " Current loss 5.9597\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 3.2367\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 2.0242\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 1.1990\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 0.8700\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 0.8602\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 0.9318\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 0.5294\n",
      "\n",
      " Validation loss: 0.5279\n",
      "\n",
      " Saved model\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 0.5221\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 10.3720\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 23.2422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 메모리 비우기\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Early Stopping과 Model Checkpoint를 위한 변수 설정\n",
    "patience = 3  # 검증 손실이 감소하지 않아도 참을 수 있는 epoch 수\n",
    "early_stopping_counter = 0\n",
    "best_loss = float('inf')\n",
    "best_model_state = None\n",
    "checkpoint_path = '../model/model2_checkpoint.pt'\n",
    "\n",
    "# Initialize lists for training and validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "net = SiameseNetwork().cuda()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001 )\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=5, factor=0.1, verbose=True)\n",
    "\n",
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "counter = []\n",
    "loss_history = []\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(Config.train_number_epochs):\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        img0, img1, label = data\n",
    "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = net(img0, img1)\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        if i % 50 == 0:\n",
    "            print(\"Epoch number {}\\n Current loss {:.4f}\\n\".format(epoch, loss_contrastive.item()))\n",
    "            iteration_number += 50\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "            \n",
    "    # Calculate validation loss\n",
    "    validation_loss = calculate_validation_loss(net, criterion, validation_dataloader)\n",
    "    print(\" Validation loss: {:.4f}\\n\".format(validation_loss))\n",
    "\n",
    "    # Save the validation loss\n",
    "    val_losses.append(validation_loss)\n",
    "        \n",
    "    # Save the best model based on validation loss\n",
    "    if validation_loss < best_loss:\n",
    "        best_loss = validation_loss\n",
    "        best_model_state = copy.deepcopy(net.state_dict())\n",
    "        # Save checkpoint\n",
    "        torch.save(best_model_state, checkpoint_path)\n",
    "        print(' Saved model\\n')\n",
    "            \n",
    "    # Check for early stopping\n",
    "    if epoch > patience and validation_loss > max(loss_history[-patience:]):\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:  \n",
    "            break\n",
    "    else:\n",
    "        early_stopping_counter = 0\n",
    "\n",
    "# Plot the training and validation losses\n",
    "plt.plot(counter, loss_history, label='Training Loss')\n",
    "plt.plot(range(len(val_losses)), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도를 계산하는 함수\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    correct = (predictions == labels).sum().item()\n",
    "    total = len(labels)\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증\n",
    "folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ]),\n",
    "                                       should_invert=False)\n",
    "\n",
    "test_dataloader = DataLoader(siamese_dataset, num_workers=0, batch_size=1, shuffle=True)\n",
    "dataiter = iter(test_dataloader)\n",
    "x0,_,_ = next(dataiter)\n",
    "\n",
    "# Load the best model\n",
    "if best_model is not None:\n",
    "    net.load_state_dict(best_model)\n",
    "\n",
    "# Load the best model from checkpoint\n",
    "checkpoint = torch.load('../model/model2_checkpoint.pt')\n",
    "net.load_state_dict(checkpoint)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "net.eval()\n",
    "test_accuracy = calculate_accuracy(net, test_dataloader)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "\n",
    "for i in range(len(dataiter)-1):\n",
    "    _,x1,label2 = next(dataiter)\n",
    "    concatenated = torch.cat((x0,x1),0)\n",
    "    \n",
    "    output1,output2 = net(Variable(x0).cuda(),Variable(x1).cuda())\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f}'.format(euclidean_distance.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
