{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각종 라이브러리를 임포트 해줍시다. \n",
    "\n",
    "%matplotlib inline\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import glob\n",
    "from PIL import ExifTags\n",
    "import shutil\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    # training_dir = \"D:/data/training/\"\n",
    "    # testing_dir = \"D:/data/testing/\"\n",
    "    # validation_dir = \"D:/data/validation/\"\n",
    "    # db_dir = \"D:/data/db/\"\n",
    "    training_dir = \"D:/non_bg/training/\"\n",
    "    testing_dir = \"D:/non_bg/testing/\"\n",
    "    validation_dir = \"D:/non_bg/validation/\"\n",
    "    db_dir = \"D:/non_bg/db/\"\n",
    "    train_batch_size = 64\n",
    "    train_number_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각종 사용할 함수를 세팅합니다.\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic', fontweight='bold',\n",
    "            bbox={'facecolor': 'white', 'alpha': 0.8, 'pad': 10})\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration, loss):\n",
    "    plt.plot(iteration, loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 경로 지정\n",
    "# folder_path = 'D:/Face_data_no_bg'\n",
    "# testing_folder = 'D:/non_bg/testing'\n",
    "# training_folder = 'D:/non_bg/training'\n",
    "# validation_folder = \"D:/non_bg/validation\"\n",
    "# val_lis = []\n",
    "\n",
    "# test_samples = 619 # testing 폴더 갯수\n",
    "# val_sampes = 309 # validation 폴더 갯수\n",
    "# random.seed(10) # 랜덤시드 고정\n",
    "\n",
    "# folders = next(os.walk(folder_path))[1] # D 드라이브에 있는 폴더를 가져오기\n",
    "# test_folders = random.sample(folders, test_samples) # testing 폴더를 랜덤으로 뽑기\n",
    "# for folder in folders:\n",
    "#     if folder not in test_folders:\n",
    "#         val_lis.append(folder)\n",
    "# val_folders = random.sample(val_lis, val_sampes) # validation 폴더를 랜덤으로 뽑기\n",
    "\n",
    "# # 폴더 생성\n",
    "# os.makedirs(training_folder, exist_ok=True)\n",
    "# os.makedirs(testing_folder, exist_ok=True)\n",
    "# os.makedirs(validation_folder, exist_ok=True)\n",
    "\n",
    "# # testing 폴더에 복사\n",
    "# for folder in test_folders:\n",
    "#     source_path = os.path.join(folder_path, folder)\n",
    "#     destination_path = os.path.join(testing_folder, folder)\n",
    "#     shutil.copytree(source_path, destination_path)\n",
    "\n",
    "# # validation 폴더에 복사\n",
    "# for folder in val_folders:\n",
    "#     source_path = os.path.join(folder_path, folder)\n",
    "#     destination_path = os.path.join(validation_folder, folder)\n",
    "#     shutil.copytree(source_path, destination_path)\n",
    "\n",
    "# # 나머지는 training 폴더에 복사\n",
    "# for folder in folders:\n",
    "#     if folder not in test_folders and folder not in val_folders:\n",
    "#         source_path = os.path.join(folder_path, folder)\n",
    "#         destination_path = os.path.join(training_folder, folder)\n",
    "#         shutil.copytree(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imageFolderDataset, transform=None, should_invert=True, testing=False):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "        self.testing = testing\n",
    "\n",
    "    def rotate(self, img):\n",
    "        try:\n",
    "            if img._getexif()[274] not in [1, 2]:\n",
    "                orientation = img._getexif()[274]\n",
    "                \n",
    "                if orientation == 2:\n",
    "                    img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "                elif orientation == 3:\n",
    "                    img = img.rotate(180)\n",
    "\n",
    "                elif orientation == 4:\n",
    "                    img = img.rotate(180).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "                elif orientation == 5:\n",
    "                    img = img.rotate(-90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "                elif orientation == 6:\n",
    "                    img = img.rotate(-90, expand=True)\n",
    "\n",
    "                elif orientation == 7:\n",
    "                    img = img.rotate(90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "            return img\n",
    "        except:\n",
    "            return img\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "        #we need to make sure approx 50% of images are in the same class\n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                #keep looping till the same class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] == img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                #keep looping till a different class image is found\n",
    "                \n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] != img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "\n",
    "        if img0._getexif() not in [1, 2]:\n",
    "            img0 = self.rotate(img0)\n",
    "        \n",
    "        if img1._getexif() not in [1, 2]:\n",
    "            img1 = self.rotate(img1)\n",
    "\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "        \n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)\n",
    "            img1 = PIL.ImageOps.invert(img1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        if self.testing:\n",
    "            name = img0_tuple[0]\n",
    "            return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32)), name\n",
    "\n",
    "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DB_Dataset():\n",
    "    def __init__(self, path, transform=None, should_invert=True):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name = os.listdir(self.path)[index]\n",
    "        img = Image.open(self.path + name)\n",
    "        img = img.convert(\"L\")\n",
    "        \n",
    "        if self.should_invert:\n",
    "            img = PIL.ImageOps.invert(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, name\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dir 경로 안의 모든 파일을 폴더명과 함께 튜플로 저장\n",
    "folder_dataset = dset.ImageFolder(root=Config.training_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.ToTensor()]),\n",
    "                                        should_invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 미니배치 생성기\n",
    "# vis_dataloader = DataLoader(siamese_dataset,\n",
    "#                         shuffle=True,\n",
    "#                         num_workers=0,\n",
    "#                         batch_size=8)\n",
    "# # 미니배치 세트 생성\n",
    "# dataiter = iter(vis_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_batch = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
    "# imshow(torchvision.utils.make_grid(concatenated))\n",
    "# print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.utils.make_grid(concatenated).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SiameseNetwork\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),            \n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  \n",
    "            \n",
    "            # nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(36*8*8, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "            nn.Linear(256, 6))\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1.7):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping을 위해 validation loss를 계산하는 함수\n",
    "def calculate_validation_loss(model, dataloader, criterion):\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs1, inputs2, labels = data\n",
    "            inputs1 = inputs1.cuda()\n",
    "            inputs2 = inputs2.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs1, outputs2 = model(inputs1, inputs2)\n",
    "            loss = criterion(outputs1, outputs2, labels)\n",
    "\n",
    "            total_loss += loss.item() * inputs1.size(0)\n",
    "            total_samples += inputs1.size(0)\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_dataset, shuffle=True, num_workers=0, \n",
    "                              batch_size=Config.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation 데이터셋\n",
    "folder_dataset_val = dset.ImageFolder(root=Config.validation_dir)\n",
    "siamese_dataset_val = SiameseNetworkDataset(imageFolderDataset=folder_dataset_val,\n",
    "                                            transform=transforms.Compose([transforms.Resize((100, 100)),\n",
    "                                                                         transforms.ToTensor()]),\n",
    "                                            should_invert=False)\n",
    "validation_dataloader = DataLoader(siamese_dataset_val, num_workers=0, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNetwork().cuda()\n",
    "criterion = ContrastiveLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "iteration_number= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " training loss 0.8079583\n",
      " validation loss: 1.5005706\n",
      "Saved model\n",
      "Epoch 2\n",
      " training loss 0.6622850\n",
      " validation loss: 0.4500224\n",
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping과 Model Checkpoint를 위한 변수 설정\n",
    "patience = 5  # 검증 손실이 감소하지 않아도 참을 수 있는 epoch 수\n",
    "early_stopping_counter = 0\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "best_model_state = None\n",
    "checkpoint_path = './model_checkpoint.pt'\n",
    "\n",
    "# Optimizer와 Scheduler 설정\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=patience, factor=0.1, verbose=True)\n",
    "\n",
    "# 학습\n",
    "for epoch in range(0, Config.train_number_epochs):\n",
    "    temp = []\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        img0, img1, label = data\n",
    "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = net(img0, img1)\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        temp.append(loss_contrastive.item())\n",
    "    \n",
    "    # 훈련용 데이터 오차\n",
    "    train_loss = np.mean(temp)\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    # 검증용 데이터로 성능 평가\n",
    "    val_loss = calculate_validation_loss(net, validation_dataloader, criterion)\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    print(\"Epoch {}\\n training loss {:.7f}\\n validation loss: {:.7f}\".format(epoch+1, train_loss, val_loss))\n",
    "\n",
    "    # 검증 손실이 더 좋아지지 않으면 카운터 증가\n",
    "    if val_loss >= best_loss:\n",
    "        early_stopping_counter += 1\n",
    "        \n",
    "        # Learning Rate 조정\n",
    "        scheduler.step(val_loss)\n",
    "    else:\n",
    "        early_stopping_counter = 0\n",
    "    \n",
    "    # 현재 검증 손실이 최저 손실보다 낮으면 모델 저장\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_state = copy.deepcopy(net.state_dict())\n",
    "        # Save checkpoint\n",
    "        torch.save(best_model_state, checkpoint_path)\n",
    "        print('Saved model')        \n",
    "            \n",
    "    # 학습 조기 종료 조건 확인\n",
    "    if early_stopping_counter >= patience:\n",
    "        \n",
    "        print(\"Early Stopping: Training stopped due to no improvement in validation loss.\")\n",
    "        break\n",
    "        \n",
    "# Plot the training and validation losses\n",
    "plt.plot(range(len(train_loss_history)), train_loss_history, label='Training Loss')\n",
    "plt.plot(range(len(val_loss_history)), val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model = None\n",
    "if best_model is not None:\n",
    "    net.load_state_dict(best_model)\n",
    "\n",
    "# Load the best model from checkpoint\n",
    "checkpoint = torch.load('./model_checkpoint.pt')\n",
    "net.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 사진 선택\n",
    "folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.ToTensor()]), \n",
    "                                        should_invert=False,\n",
    "                                        testing=True)\n",
    "test_dataloader = DataLoader(siamese_dataset, num_workers=0, batch_size=1, shuffle=True)\n",
    "\n",
    "dataiter = iter(test_dataloader)\n",
    "x0, _, _, img_name = next(dataiter)\n",
    "img_name = img_name[0].split('/')[-1].split('\\\\')[0]\n",
    "imshow(torchvision.utils.make_grid(x0))\n",
    "print(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 이미지 로드\n",
    "db_dataset = DB_Dataset(path=Config.db_dir, \n",
    "                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                      transforms.ToTensor()]), \n",
    "                        should_invert=False)\n",
    "db_dataloader = DataLoader(db_dataset, num_workers=0, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB에서 일치하는 사진 탐색\n",
    "dataiter = iter(db_dataloader)\n",
    "min_distance = np.inf\n",
    "idx=0\n",
    "for i in range(db_dataset.__len__()):\n",
    "    \n",
    "    x1, label = next(dataiter)\n",
    "    concatenated = torch.cat((x0,x1), 0)\n",
    "    \n",
    "    output1, output2 = net(Variable(x0).cuda(), Variable(x1).cuda())\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    \n",
    "    if euclidean_distance <= min_distance:\n",
    "        min_distance = euclidean_distance\n",
    "        imgset = concatenated\n",
    "        name = label[0]\n",
    "        \n",
    "# if min_distance.item() <= 0.3:\n",
    "#     imshow(torchvision.utils.make_grid(imgset), 'Dissimilarity: {:.2f}'.format(min_distance.item()))\n",
    "#     print(f'name: {name}')\n",
    "# else:\n",
    "#     print('none')\n",
    "imshow(torchvision.utils.make_grid(imgset), 'Dissimilarity: {:.2f}'.format(min_distance.item()))\n",
    "print(f'test iamge name: {img_name}.jpg \\t   database image name: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
